{
 "cells": [
  {
   "cell_type": "code",
   "id": "ed756e3d-2a17-4ba6-8f70-b5b31d2a1567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.465942Z",
     "start_time": "2024-07-20T16:50:22.319985Z"
    }
   },
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import sklearn.metrics\n",
    "import dill as pickle\n",
    "import json\n",
    "\n",
    "import optuna\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.506785Z",
     "start_time": "2024-07-20T16:50:23.467293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATABASE_URL = \"postgresql+psycopg2://postgres:postgres@localhost:5432/postgres\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ],
   "id": "b7f9fa04333d5ccd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f1c6802f-582a-4e79-a590-8f64a3f91d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.510569Z",
     "start_time": "2024-07-20T16:50:23.507729Z"
    }
   },
   "source": [
    "fe_query = text(\"\"\"\n",
    "WITH all_combinations AS (\n",
    "    SELECT c.customer_id, \n",
    "           d.purchase_date_id\n",
    "    FROM (SELECT DISTINCT customer_id FROM customer) AS c\n",
    "    CROSS JOIN (SELECT DISTINCT date_trunc('month', purchase_date) AS purchase_date_id FROM transaction) AS d\n",
    "),\n",
    "agg_data AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        date_trunc('month', purchase_date) AS purchase_date_id,\n",
    "        SUM(purchase_amount) AS total_purchase_amount,\n",
    "        AVG(purchase_amount) AS mean_purchase_amount,\n",
    "        MAX(purchase_amount) AS max_purchase_amount,\n",
    "        MIN(purchase_amount) AS min_purchase_amount,\n",
    "        COUNT(purchase_amount) AS count_purchase_amount\n",
    "    FROM transaction\n",
    "    GROUP BY customer_id, purchase_date_id\n",
    "),\n",
    "combined_data AS (\n",
    "    SELECT \n",
    "        ac.customer_id,\n",
    "        ac.purchase_date_id,\n",
    "        COALESCE(ad.total_purchase_amount, 0) AS purchase_amount,\n",
    "        COALESCE(ad.mean_purchase_amount, 0) AS purchase_amount_mean,\n",
    "        COALESCE(ad.max_purchase_amount, 0) AS purchase_amount_max,\n",
    "        COALESCE(ad.min_purchase_amount, 0) AS purchase_amount_min,\n",
    "        COALESCE(ad.count_purchase_amount, 0) AS purchase_amount_count\n",
    "    FROM all_combinations AS ac\n",
    "    LEFT JOIN agg_data AS ad ON ac.customer_id = ad.customer_id \n",
    "                              AND ac.purchase_date_id = ad.purchase_date_id\n",
    "),\n",
    "cumulative_data AS (\n",
    "    SELECT *,\n",
    "           SUM(COALESCE(purchase_amount_count, 0)) OVER (PARTITION BY customer_id ORDER BY purchase_date_id) AS total_transaction,\n",
    "           LEAD(purchase_amount) OVER (PARTITION BY customer_id ORDER BY purchase_date_id) AS next_month_purchase_amount\n",
    "    FROM combined_data\n",
    ")\n",
    "SELECT c.*,\n",
    "        cd.purchase_date_id, \n",
    "       cd.purchase_amount,\n",
    "       cd.purchase_amount_mean,\n",
    "       cd.purchase_amount_max,\n",
    "       cd.purchase_amount_min,\n",
    "       cd.purchase_amount_count,\n",
    "       cd.total_transaction, \n",
    "       cd.next_month_purchase_amount\n",
    "FROM customer AS c\n",
    "LEFT JOIN cumulative_data AS cd ON c.customer_id = cd.customer_id\n",
    "WHERE cd.next_month_purchase_amount IS NOT NULL\n",
    "ORDER BY c.customer_id, cd.purchase_date_id;\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "26cc78e7-f543-4de2-96e1-ae2bca639996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.880152Z",
     "start_time": "2024-07-20T16:50:23.511332Z"
    }
   },
   "source": [
    "df = pd.read_sql(fe_query, session.bind)\n",
    "display(df.head())\n",
    "session.close()\n",
    "engine.dispose()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   customer_id   age  gender  annual_income          purchase_date_id  \\\n",
       "0            1  40.0     1.0       119228.0 2023-05-01 00:00:00+00:00   \n",
       "1            1  40.0     1.0       119228.0 2023-06-01 00:00:00+00:00   \n",
       "2            1  40.0     1.0       119228.0 2023-07-01 00:00:00+00:00   \n",
       "3            1  40.0     1.0       119228.0 2023-08-01 00:00:00+00:00   \n",
       "4            1  40.0     1.0       119228.0 2023-09-01 00:00:00+00:00   \n",
       "\n",
       "   purchase_amount  purchase_amount_mean  purchase_amount_max  \\\n",
       "0             0.00                  0.00                 0.00   \n",
       "1             0.00                  0.00                 0.00   \n",
       "2           725.54                362.77               629.34   \n",
       "3             0.00                  0.00                 0.00   \n",
       "4             0.00                  0.00                 0.00   \n",
       "\n",
       "   purchase_amount_min  purchase_amount_count  total_transaction  \\\n",
       "0                  0.0                      0                0.0   \n",
       "1                  0.0                      0                0.0   \n",
       "2                 96.2                      2                2.0   \n",
       "3                  0.0                      0                2.0   \n",
       "4                  0.0                      0                2.0   \n",
       "\n",
       "   next_month_purchase_amount  \n",
       "0                        0.00  \n",
       "1                      725.54  \n",
       "2                        0.00  \n",
       "3                        0.00  \n",
       "4                     2023.40  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>purchase_date_id</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_amount_mean</th>\n",
       "      <th>purchase_amount_max</th>\n",
       "      <th>purchase_amount_min</th>\n",
       "      <th>purchase_amount_count</th>\n",
       "      <th>total_transaction</th>\n",
       "      <th>next_month_purchase_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119228.0</td>\n",
       "      <td>2023-05-01 00:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119228.0</td>\n",
       "      <td>2023-06-01 00:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>725.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119228.0</td>\n",
       "      <td>2023-07-01 00:00:00+00:00</td>\n",
       "      <td>725.54</td>\n",
       "      <td>362.77</td>\n",
       "      <td>629.34</td>\n",
       "      <td>96.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119228.0</td>\n",
       "      <td>2023-08-01 00:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119228.0</td>\n",
       "      <td>2023-09-01 00:00:00+00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "9d115543-9929-4f2d-89d9-8fd62dada174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.884800Z",
     "start_time": "2024-07-20T16:50:23.882317Z"
    }
   },
   "source": [
    "class CFG:\n",
    "    label = \"next_month_purchase_amount\"\n",
    "    id_cols = [\"customer_id\", \"purchase_date_id\"]\n",
    "    FOLD_CNT = 5\n",
    "    SEED = 42\n",
    "    DEVICE = \"CPU\"\n",
    "    ITERATION = 20000\n",
    "    TUNE = True\n",
    "    EVAL_METRIC = \"r2_score\"\n",
    "    N_TRIAL = 5"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "100d99e9-57f2-4c0b-a97a-f86774697cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.896227Z",
     "start_time": "2024-07-20T16:50:23.885784Z"
    }
   },
   "source": [
    "class HyperparameterSearch:\n",
    "    \"\"\"\n",
    "    Class for hyperparameter optimization using Optuna.\n",
    "\n",
    "    Attributes:\n",
    "    - model_name (str): Name of the model to optimize hyperparameters for.\n",
    "    - best_params (dict): Best hyperparameters found during optimization.\n",
    "    - best_score (float): Best score achieved during optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        \"\"\"\n",
    "        Initialize the HyperparameterSearch object.\n",
    "\n",
    "        Args:\n",
    "        - model_name (str): Name of the model to optimize hyperparameters for.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "\n",
    "    def objective(self, trial, data, target):\n",
    "        \"\"\"\n",
    "        Objective function for hyperparameter optimization.\n",
    "\n",
    "        Args:\n",
    "        - trial (optuna.Trial): The current trial.\n",
    "        - data (list of tuples): List of tuples containing train and validation indices.\n",
    "        - target (str): Name of the target column.\n",
    "\n",
    "        Returns:\n",
    "        - float: Mean F1 score for the given hyperparameters.\n",
    "        \"\"\"\n",
    "\n",
    "        params = {\n",
    "            \"CatBoost\": {\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "                \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "                \"bagging_temperature\": trial.suggest_int(\"bagging_temperature\", 1, 7),\n",
    "                \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 10),\n",
    "                \"grow_policy\": trial.suggest_categorical(\n",
    "                    \"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]\n",
    "                ),\n",
    "                \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 1, 10),\n",
    "\n",
    "                \"model_shrink_mode\": trial.suggest_categorical(\n",
    "                    \"model_shrink_mode\", [\"Constant\", \"Decreasing\"]\n",
    "                ),\n",
    "                \"penalties_coefficient\": trial.suggest_float(\n",
    "                    \"penalties_coefficient\", 0, 6\n",
    "                ),\n",
    "                \"model_shrink_rate\": trial.suggest_float(\"model_shrink_rate\", 0, 1),\n",
    "                \"random_strength\": trial.suggest_float(\"random_strength\", 0, 10),\n",
    "                \"task_type\": \"CPU\",\n",
    "                \"devices\": \"0:1\",\n",
    "                \"iterations\": 1000,\n",
    "                \"random_state\": 42,\n",
    "                \"early_stopping_rounds\": 200,\n",
    "                \"thread_count\": -1,\n",
    "                \"allow_writing_files\": False,\n",
    "                \"has_time\": False,\n",
    "                \"verbose\": False,\n",
    "            },\n",
    "            \"LGBM\": {\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "                \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 20),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0, 1),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "                \"n_estimators\": 1000,\n",
    "                \"random_state\": 42,\n",
    "                \"early_stopping_rounds\": 200,\n",
    "                \"verbosity\": -1,\n",
    "            },\n",
    "            \"XGB\": {\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "                \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0, 1),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "                \"n_estimators\": 1000,\n",
    "                \"random_state\": 42,\n",
    "                \"early_stopping_rounds\": 200,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        model = eval(f\"{self.model_name}Regressor\")(**params[self.model_name])\n",
    "\n",
    "        scores = []\n",
    "        for train_idx, val_idx in data:\n",
    "            model.fit(\n",
    "                X.loc[train_idx],\n",
    "                y.loc[train_idx],\n",
    "                eval_set=[(X.loc[val_idx], y.loc[val_idx])],\n",
    "            )\n",
    "\n",
    "            preds = model.predict(X.loc[val_idx])\n",
    "\n",
    "            score = sklearn.metrics.mean_squared_error(y.loc[val_idx], preds)\n",
    "            scores.append(score)\n",
    "\n",
    "        cv_score = np.mean(scores)\n",
    "        print(\"#\" * 50)\n",
    "        print(\"TRIAL CV SCORE: \", cv_score)\n",
    "\n",
    "        return cv_score\n",
    "\n",
    "    def optimize(self, data, target, n_trials=100):\n",
    "        \"\"\"\n",
    "        Perform hyperparameter optimization.\n",
    "\n",
    "        Args:\n",
    "        - data (list of tuples): List of tuples containing train and validation indices.\n",
    "        - target (str): Name of the target column.\n",
    "        - n_trials (int): Number of optimization trials.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: A tuple containing the best hyperparameters and the best score.\n",
    "        \"\"\"\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(\n",
    "            lambda trial: self.objective(trial, data, target), n_trials=n_trials\n",
    "        )\n",
    "        self.best_params = study.best_params\n",
    "        self.best_score = study.best_value\n",
    "\n",
    "        print(f\"Best {self.model_name} params: {self.best_params}\")\n",
    "        print(f\"Best {self.model_name} score: {self.best_score}\")\n",
    "\n",
    "        return self.best_params, self.best_score"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "37321cb3-e2b9-4afa-93c8-4c53f3b195b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.908116Z",
     "start_time": "2024-07-20T16:50:23.897342Z"
    }
   },
   "source": [
    "cv = KFold(n_splits=CFG.FOLD_CNT, shuffle=True, random_state=CFG.SEED)\n",
    "cv_splits = list(cv.split(df.index, df.loc[:, CFG.label].astype(str)))"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:50:23.912608Z",
     "start_time": "2024-07-20T16:50:23.909089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def param_space(model_name):\n",
    "    space = {\n",
    "        \"CatBoost\": [\n",
    "            \"learning_rate\",\n",
    "            \"depth\",\n",
    "            \"bagging_temperature\",\n",
    "            \"min_data_in_leaf\",\n",
    "            \"grow_policy\",\n",
    "            \"l2_leaf_reg\",\n",
    "            \"model_shrink_mode\",\n",
    "            \"penalties_coefficient\",\n",
    "            \"model_shrink_rate\",\n",
    "            \"random_strength\",\n",
    "            \"task_type\",\n",
    "            \"devices\",\n",
    "            \"iterations\",\n",
    "            \"random_state\",\n",
    "            \"early_stopping_rounds\",\n",
    "            \"thread_count\",\n",
    "            \"allow_writing_files\",\n",
    "            \"eval_metric\",\n",
    "            \"has_time\",\n",
    "            \"verbose\",\n",
    "        ],\n",
    "        \"LGBM\": [\n",
    "            \"learning_rate\",\n",
    "            \"max_depth\",\n",
    "            \"min_child_samples\",\n",
    "            \"colsample_bytree\",\n",
    "            \"reg_alpha\",\n",
    "            \"reg_lambda\",\n",
    "            \"n_estimators\",\n",
    "            \"random_state\",\n",
    "            \"early_stopping_rounds\",\n",
    "            \"eval_metric\",\n",
    "            \"verbosity\",\n",
    "        ],\n",
    "        \"XGB\": [\n",
    "            \"learning_rate\",\n",
    "            \"max_depth\",\n",
    "            \"min_child_weight\",\n",
    "            \"colsample_bytree\",\n",
    "            \"reg_alpha\",\n",
    "            \"reg_lambda\",\n",
    "            \"n_estimators\",\n",
    "            \"random_state\",\n",
    "            \"early_stopping_rounds\",\n",
    "            \"eval_metric\",\n",
    "        ],\n",
    "    }\n",
    "    return space[model_name]"
   ],
   "id": "8e296d0c09ae00dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if CFG.TUNE:\n",
    "    X = df.drop(CFG.id_cols + [CFG.label], axis=1).reset_index(drop=True)\n",
    "    y = df[CFG.label].reset_index(drop=True)\n",
    "\n",
    "    search_results = {}\n",
    "\n",
    "    for model in [\"CatBoost\", \"LGBM\", \"XGB\"]:\n",
    "\n",
    "        hyperparam_search = HyperparameterSearch(model)\n",
    "        best_params, best_score = hyperparam_search.optimize(\n",
    "            cv_splits, y, n_trials=CFG.N_TRIAL\n",
    "        )\n",
    "        search_results[model] = {}\n",
    "        search_results[model][\"best_params\"] = best_params\n",
    "        search_results[model][\"best_score\"] = best_score\n",
    "    best_model_name = max(search_results, key=lambda x: search_results[x][\"best_score\"])\n",
    "    params = {\n",
    "        key: value\n",
    "        for key, value in search_results[best_model_name][\"best_params\"].items()\n",
    "        if key in param_space(best_model_name)\n",
    "    }\n",
    "\n",
    "    clear_output()\n",
    "else:\n",
    "    best_model_name = \"LGBM\"\n",
    "    params = {'learning_rate': 0.3145612178433824,\n",
    "         'max_depth': 1,\n",
    "         'min_child_samples': 20,\n",
    "         'colsample_bytree': 0.8675872845213625,\n",
    "         'reg_alpha': 0.05192113452495395,\n",
    "         'reg_lambda': 0.2671944984727639}\n"
   ],
   "id": "6dde48f1109a62e6",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:14.129891Z",
     "start_time": "2024-07-20T16:51:14.124108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ModelManager:\n",
    "    \"\"\"\n",
    "    Class for managing models, including training, exporting, and loading.\n",
    "\n",
    "    Attributes:\n",
    "    - model_name (str): Name of the model to be used (e.g., \"CatBoost\", \"LGBM\", \"XGB\").\n",
    "    - model_directory (str): Directory to save/load models.\n",
    "    - models (list): List of trained models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name, model_directory=\"models\", models=[]):\n",
    "        \"\"\"\n",
    "        Initialize the ModelManager object.\n",
    "\n",
    "        Args:\n",
    "        - model_name (str): Name of the model to be used.\n",
    "        - model_directory (str): Directory to save/load models.\n",
    "        - models (list): List of trained models.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.models = models\n",
    "        self.model_directory = model_directory\n",
    "\n",
    "    def train_models(self, data, target, params):\n",
    "        \"\"\"\n",
    "        Train models using cross-validation.\n",
    "\n",
    "        Args:\n",
    "        - data (DataFrame): Input features.\n",
    "        - target (Series): Target variable.\n",
    "        - params (dict): Parameters for the model.\n",
    "        - cv_splits (list of tuples): List of tuples containing train and validation indices.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        if self.model_name == \"CatBoost\":\n",
    "            model = CatBoostRegressor(**params)\n",
    "        elif self.model_name == \"LGBM\":\n",
    "            model = LGBMRegressor(**params)\n",
    "        elif self.model_name == \"XGB\":\n",
    "            model = XGBRegressor(**params)\n",
    "\n",
    "        model.fit(data, target) # todo: cross-validation and log best fold \n",
    "        \n",
    "        self.models.append(model)\n",
    "\n",
    "    def get_models(self):\n",
    "        \"\"\"\n",
    "        Get the list of trained models.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of trained models.\n",
    "        \"\"\"\n",
    "        return self.models\n",
    "\n",
    "    def export_models(self):\n",
    "        \"\"\"\n",
    "        Export trained models to files in the specified directory.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.model_directory):\n",
    "            os.makedirs(self.model_directory)\n",
    "\n",
    "        for idx, model in enumerate(self.models):\n",
    "            filename = os.path.join(self.model_directory, f\"Model_{idx}.pkl\")\n",
    "            with open(filename, \"wb\") as file:\n",
    "                pickle.dump(model, file)\n",
    "\n",
    "    def load_models(self):\n",
    "        \"\"\"\n",
    "        Load models from files in the specified directory.\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "        for filename in os.listdir(self.model_directory):\n",
    "            if \"Model\" in filename:\n",
    "                with open(os.path.join(self.model_directory, filename), \"rb\") as file:\n",
    "                    model = pickle.load(file)\n",
    "                    self.models.append(model)"
   ],
   "id": "32604c308b77507e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:14.132283Z",
     "start_time": "2024-07-20T16:51:14.130599Z"
    }
   },
   "cell_type": "code",
   "source": "model_manager = ModelManager(best_model_name)\n",
   "id": "24b30f2507718208",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:14.135338Z",
     "start_time": "2024-07-20T16:51:14.132954Z"
    }
   },
   "cell_type": "code",
   "source": "feat_cols = list(df.columns.difference(set(CFG.id_cols + [CFG.label])))",
   "id": "396b4ae44852f8f7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_manager.train_models(df[feat_cols], df[CFG.label], params)\n",
    "clear_output()"
   ],
   "id": "72a20bf423dc9bef",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:18.391899Z",
     "start_time": "2024-07-20T16:51:18.386802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_manager.export_models()\n",
    "model_manager = ModelManager(best_model_name)\n",
    "config = {\n",
    "    \"best_model_name\": best_model_name,\n",
    "    \"feat_cols\": feat_cols,\n",
    "    \"params\": params,\n",
    "    \"label\": CFG.label,\n",
    "    \"id_cols\": CFG.id_cols,\n",
    "    \"FOLD_CNT\": CFG.FOLD_CNT,\n",
    "    \"SEED\": CFG.SEED,\n",
    "    \"DEVICE\": CFG.DEVICE,\n",
    "    \"ITERATION\": CFG.ITERATION,\n",
    "    \"TUNE\": CFG.TUNE,\n",
    "    \"EVAL_METRIC\": CFG.EVAL_METRIC,\n",
    "    \"N_TRIAL\": CFG.N_TRIAL,\n",
    "}\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(config, f)"
   ],
   "id": "5bec8f6f3274c2c8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:18.396031Z",
     "start_time": "2024-07-20T16:51:18.392844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_inference_data(params):\n",
    "    inference_query = text(\"\"\"\n",
    "    WITH all_combinations AS (\n",
    "        SELECT c.customer_id, \n",
    "               d.purchase_date_id\n",
    "        FROM (SELECT DISTINCT customer_id FROM customer) AS c\n",
    "        CROSS JOIN (SELECT DISTINCT date_trunc('month', purchase_date) AS purchase_date_id FROM transaction) AS d\n",
    "    ),\n",
    "    agg_data AS (\n",
    "        SELECT \n",
    "            customer_id,\n",
    "            date_trunc('month', purchase_date) AS purchase_date_id,\n",
    "            SUM(purchase_amount) AS total_purchase_amount,\n",
    "            AVG(purchase_amount) AS mean_purchase_amount,\n",
    "            MAX(purchase_amount) AS max_purchase_amount,\n",
    "            MIN(purchase_amount) AS min_purchase_amount,\n",
    "            COUNT(purchase_amount) AS count_purchase_amount\n",
    "        FROM transaction\n",
    "        GROUP BY customer_id, purchase_date_id\n",
    "    ),\n",
    "    combined_data AS (\n",
    "        SELECT \n",
    "            ac.customer_id,\n",
    "            ac.purchase_date_id,\n",
    "            COALESCE(ad.total_purchase_amount, 0) AS purchase_amount,\n",
    "            COALESCE(ad.mean_purchase_amount, 0) AS purchase_amount_mean,\n",
    "            COALESCE(ad.max_purchase_amount, 0) AS purchase_amount_max,\n",
    "            COALESCE(ad.min_purchase_amount, 0) AS purchase_amount_min,\n",
    "            COALESCE(ad.count_purchase_amount, 0) AS purchase_amount_count\n",
    "        FROM all_combinations AS ac\n",
    "        LEFT JOIN agg_data AS ad ON ac.customer_id = ad.customer_id \n",
    "                                  AND ac.purchase_date_id = ad.purchase_date_id\n",
    "    ),\n",
    "    cumulative_data AS (\n",
    "        SELECT *,\n",
    "               SUM(COALESCE(purchase_amount_count, 0)) OVER (PARTITION BY customer_id ORDER BY purchase_date_id) AS total_transaction,\n",
    "               LEAD(purchase_amount) OVER (PARTITION BY customer_id ORDER BY purchase_date_id) AS next_month_purchase_amount\n",
    "        FROM combined_data\n",
    "    )\n",
    "    SELECT c.*, \n",
    "           cd.purchase_amount,\n",
    "           cd.purchase_amount_mean,\n",
    "           cd.purchase_amount_max,\n",
    "           cd.purchase_amount_min,\n",
    "           cd.purchase_amount_count,\n",
    "           cd.total_transaction, \n",
    "           cd.next_month_purchase_amount\n",
    "    FROM customer AS c\n",
    "    LEFT JOIN cumulative_data AS cd ON c.customer_id = cd.customer_id\n",
    "    WHERE cd.next_month_purchase_amount IS NOT NULL\n",
    "      AND cd.customer_id = :customer_id\n",
    "      AND cd.purchase_date_id = :purchase_date_id\n",
    "    ORDER BY c.customer_id, cd.purchase_date_id;\n",
    "    \"\"\")\n",
    "\n",
    "    result = pd.read_sql(inference_query, session.bind, params=params)\n",
    "    \n",
    "    return result\n"
   ],
   "id": "5dc409ea527b1135",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:18.400186Z",
     "start_time": "2024-07-20T16:51:18.396872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Inference:\n",
    "    \"\"\"\n",
    "    Class for performing inference using trained models.\n",
    "\n",
    "    Attributes:\n",
    "    - config (dict): Configuration dictionary containing model information.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the Inference object.\n",
    "\n",
    "        Args:\n",
    "        - config (dict): Configuration dictionary containing model information.\n",
    "        \"\"\"\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "    def train_inference(self, data):\n",
    "        \"\"\"\n",
    "        Train the inference model.\n",
    "\n",
    "        Args:\n",
    "        - data (DataFrame): Training data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def test_inference(self, data):\n",
    "        \"\"\"\n",
    "        Perform inference on test data.\n",
    "\n",
    "        Args:\n",
    "        - data (dict): Dictionary containing the input data for inference.\n",
    "\n",
    "        Returns:\n",
    "        - int: Predicted label based on the majority vote of individual model predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        model_manager = ModelManager(self.config[\"best_model_name\"])\n",
    "        model_manager.load_models()\n",
    "        data = get_inference_data(data)[self.config[\"feat_cols\"]]\n",
    "        \n",
    "        preds = []\n",
    "        for idx, model in enumerate(model_manager.models):\n",
    "            pred = model.predict(data)\n",
    "            preds.append(pred)\n",
    "\n",
    "        return np.mean(preds)"
   ],
   "id": "1c6a7f4b5f5c2bfb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:18.437719Z",
     "start_time": "2024-07-20T16:51:18.400901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inference = Inference(config)\n",
    "data = {\n",
    "    \"customer_id\":1,\n",
    "    \"purchase_date_id\":\"2024-01-01\"\n",
    "}\n",
    "inference.test_inference(data)"
   ],
   "id": "8b598b14f65dce33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259.079028535477"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T16:51:18.440092Z",
     "start_time": "2024-07-20T16:51:18.438564Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "45f284f3e6c45181",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
